{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6849ca",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 1: ENVIRONMENT SETUP & IMPORTS\n",
    "**Function:** `setup_environment()`\n",
    "\n",
    "**Purpose:** Import all required libraries and set configuration parameters\n",
    "\n",
    "**Inputs:** None\n",
    "\n",
    "**Outputs:** Imported modules and libraries\n",
    "\n",
    "**Dependencies:** None (first step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import joblib\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Model selection and validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    log_loss,\n",
    "    cohen_kappa_score,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "\n",
    "# Resampling\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Statistical tests\n",
    "from scipy.stats import anderson, zscore\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "\n",
    "# Configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"✓ Environment setup complete\")\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39654a",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 2: DATA LOADING & VALIDATION\n",
    "**Function:** `load_data(train_path, test_path)`\n",
    "\n",
    "**Purpose:** Load training and test datasets from CSV files with basic validation\n",
    "\n",
    "**Inputs:**\n",
    "- `train_path` (str): Path to training dataset\n",
    "- `test_path` (str): Path to test dataset\n",
    "\n",
    "**Outputs:**\n",
    "- `train_df` (pd.DataFrame): Training dataset\n",
    "- `test_df` (pd.DataFrame): Test dataset\n",
    "\n",
    "**Dependencies:** None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_path = 'churn-bigml-80.csv'\n",
    "test_path = 'churn-bigml-20.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA LOADING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
    "print(\"\\n✓ Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbd0d9f",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 3: DATA QUALITY VALIDATION\n",
    "**Function:** `validate_data_quality(df, dataset_name)`\n",
    "\n",
    "**Purpose:** Perform comprehensive data quality checks\n",
    "\n",
    "**Inputs:**\n",
    "- `df` (pd.DataFrame): Dataset to validate\n",
    "- `dataset_name` (str): Name for logging\n",
    "\n",
    "**Outputs:**\n",
    "- `quality_report` (dict): Dictionary with quality metrics\n",
    "\n",
    "**Dependencies:** BLOCK 2 (requires loaded data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data_quality(df, dataset_name=\"Dataset\"):\n",
    "    \"\"\"Validate data quality and return comprehensive report\"\"\"\n",
    "    report = {\n",
    "        'dataset_name': dataset_name,\n",
    "        'shape': df.shape,\n",
    "        'missing_values': df.isna().sum().to_dict(),\n",
    "        'duplicate_count': df.duplicated().sum(),\n",
    "        'data_types': df.dtypes.to_dict(),\n",
    "        'unique_counts': df.nunique().to_dict()\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{dataset_name.upper()} - DATA QUALITY REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Shape: {report['shape']}\")\n",
    "    print(f\"Missing values: {sum(report['missing_values'].values())} total\")\n",
    "    print(f\"Duplicate rows: {report['duplicate_count']}\")\n",
    "    print(f\"\\nData types:\\n{df.dtypes.value_counts()}\")\n",
    "    print(\"\\n✓ Data quality validation complete\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Validate both datasets\n",
    "train_report = validate_data_quality(train_df, \"Training Set\")\n",
    "test_report = validate_data_quality(test_df, \"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e07100",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 4: EXPLORATORY DATA ANALYSIS (EDA)\n",
    "**Function:** `perform_eda(df, target_col, save_plots)`\n",
    "\n",
    "**Purpose:** Generate comprehensive EDA visualizations and statistics\n",
    "\n",
    "**Inputs:**\n",
    "- `df` (pd.DataFrame): Dataset to analyze\n",
    "- `target_col` (str): Target column name\n",
    "- `save_plots` (bool): Whether to save plots\n",
    "\n",
    "**Outputs:**\n",
    "- `eda_summary` (dict): Statistical summary\n",
    "- Visualization files (optional)\n",
    "\n",
    "**Dependencies:** BLOCK 2 (requires loaded data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(train_df.describe())\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = [\"State\", \"Area code\", \"International plan\", \"Voice mail plan\", \n",
    "                    \"Customer service calls\", \"Churn\"]\n",
    "numerical_cols = [col for col in train_df.columns if col not in categorical_cols]\n",
    "\n",
    "print(f\"\\nCategorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical features\n",
    "plt.figure(figsize=(15, 40))\n",
    "plot_num = 1\n",
    "for col in categorical_cols:\n",
    "    plt.subplot(10, 2, plot_num)\n",
    "    sns.countplot(data=train_df, x=col)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plot_num += 1\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Categorical features visualized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numerical features\n",
    "plt.figure(figsize=(15, 40))\n",
    "plot_num = 1\n",
    "for col in numerical_cols:\n",
    "    plt.subplot(10, 2, plot_num)\n",
    "    sns.histplot(data=train_df, x=col, bins=25)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plot_num += 1\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Numerical features visualized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60966fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize churn distribution by categorical features\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.countplot(x='State', hue='Churn', data=train_df, palette='Set2')\n",
    "plt.title('Churn Distribution by State', fontsize=16)\n",
    "plt.xlabel('State', fontsize=14)\n",
    "plt.ylabel('Count of Customers', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.countplot(x='Customer service calls', hue='Churn', data=train_df, palette='Set2')\n",
    "plt.title('Churn Distribution by Customer Service Calls', fontsize=16)\n",
    "plt.xlabel('Number of Service Calls', fontsize=14)\n",
    "plt.ylabel('Count of Customers', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Churn distribution analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64da579a",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 5: CATEGORICAL ENCODING\n",
    "**Function:** `encode_categorical_features(train_df, test_df, binary_cols, onehot_cols)`\n",
    "\n",
    "**Purpose:** Encode categorical variables using appropriate strategies\n",
    "\n",
    "**Inputs:**\n",
    "- `train_df` (pd.DataFrame): Training dataset\n",
    "- `test_df` (pd.DataFrame): Test dataset\n",
    "- `binary_cols` (list): Columns for binary encoding\n",
    "- `onehot_cols` (list): Columns for one-hot encoding\n",
    "\n",
    "**Outputs:**\n",
    "- `train_encoded` (pd.DataFrame): Encoded training data\n",
    "- `test_encoded` (pd.DataFrame): Encoded test data\n",
    "- `encoders` (dict): Fitted encoder objects\n",
    "\n",
    "**Dependencies:** BLOCK 2 (requires loaded data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac4a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CATEGORICAL ENCODING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create copies to avoid modifying originals\n",
    "train_encoded = train_df.copy()\n",
    "test_encoded = test_df.copy()\n",
    "\n",
    "# Step 1: Convert target to binary integer\n",
    "train_encoded['Churn'] = train_encoded['Churn'].astype(int)\n",
    "test_encoded['Churn'] = test_encoded['Churn'].astype(int)\n",
    "print(\"✓ Target variable encoded (False=0, True=1)\")\n",
    "\n",
    "# Step 2: Binary encoding for Yes/No columns\n",
    "binary_mapping = {'No': 0, 'Yes': 1}\n",
    "train_encoded['International plan'] = train_encoded['International plan'].map(binary_mapping)\n",
    "test_encoded['International plan'] = test_encoded['International plan'].map(binary_mapping)\n",
    "\n",
    "train_encoded['Voice mail plan'] = train_encoded['Voice mail plan'].map(binary_mapping)\n",
    "test_encoded['Voice mail plan'] = test_encoded['Voice mail plan'].map(binary_mapping)\n",
    "print(\"✓ Binary features encoded (No=0, Yes=1)\")\n",
    "\n",
    "# Step 3: One-Hot Encoding for State and Area Code\n",
    "encoders = {}\n",
    "\n",
    "# State encoder\n",
    "encoder_state = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_states_train = encoder_state.fit_transform(train_encoded[['State']])\n",
    "encoded_states_test = encoder_state.transform(test_encoded[['State']])\n",
    "\n",
    "state_columns = encoder_state.get_feature_names_out(['State'])\n",
    "train_states_df = pd.DataFrame(encoded_states_train, columns=state_columns, index=train_encoded.index)\n",
    "test_states_df = pd.DataFrame(encoded_states_test, columns=state_columns, index=test_encoded.index)\n",
    "\n",
    "# Area code encoder\n",
    "encoder_area = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_area_train = encoder_area.fit_transform(train_encoded[['Area code']])\n",
    "encoded_area_test = encoder_area.transform(test_encoded[['Area code']])\n",
    "\n",
    "area_columns = encoder_area.get_feature_names_out(['Area code'])\n",
    "train_area_df = pd.DataFrame(encoded_area_train, columns=area_columns, index=train_encoded.index)\n",
    "test_area_df = pd.DataFrame(encoded_area_test, columns=area_columns, index=test_encoded.index)\n",
    "\n",
    "# Remove original columns and concatenate encoded ones\n",
    "train_encoded = train_encoded.drop(['State', 'Area code'], axis=1)\n",
    "test_encoded = test_encoded.drop(['State', 'Area code'], axis=1)\n",
    "\n",
    "train_encoded = pd.concat([train_encoded, train_states_df, train_area_df], axis=1)\n",
    "test_encoded = pd.concat([test_encoded, test_states_df, test_area_df], axis=1)\n",
    "\n",
    "# Store encoders\n",
    "encoders['state_encoder'] = encoder_state\n",
    "encoders['area_encoder'] = encoder_area\n",
    "\n",
    "print(f\"✓ One-hot encoding complete\")\n",
    "print(f\"  - State: {len(state_columns)} features\")\n",
    "print(f\"  - Area code: {len(area_columns)} features\")\n",
    "print(f\"\\nFinal shapes:\")\n",
    "print(f\"  Training: {train_encoded.shape}\")\n",
    "print(f\"  Test: {test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3be7463",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 6: OUTLIER DETECTION & REMOVAL\n",
    "**Function:** `remove_outliers(df, method, columns)`\n",
    "\n",
    "**Purpose:** Detect and remove outliers using statistical methods\n",
    "\n",
    "**Inputs:**\n",
    "- `df` (pd.DataFrame): Dataset to clean\n",
    "- `method` (str): 'zscore' or 'iqr'\n",
    "- `columns` (list): Columns to check for outliers\n",
    "\n",
    "**Outputs:**\n",
    "- `df_cleaned` (pd.DataFrame): Dataset without outliers\n",
    "- `outlier_report` (dict): Summary of removed data\n",
    "\n",
    "**Dependencies:** BLOCK 5 (requires encoded data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1469a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"OUTLIER DETECTION & REMOVAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define columns to check for outliers\n",
    "outlier_columns = [\n",
    "    'Account length', 'Total day minutes', 'Total day calls', 'Total day charge',\n",
    "    'Total eve minutes', 'Total eve calls', 'Total eve charge',\n",
    "    'Total night minutes', 'Total night calls', 'Total night charge',\n",
    "    'Total intl minutes', 'Total intl calls', 'Total intl charge'\n",
    "]\n",
    "\n",
    "# Visualize outliers before removal\n",
    "plt.figure(figsize=(20, 15))\n",
    "for i, column in enumerate(outlier_columns, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.boxplot(data=train_encoded, y=column, color='skyblue')\n",
    "    plt.title(f'{column}')\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Outliers - Before Removal', fontsize=16, y=1.001)\n",
    "plt.show()\n",
    "\n",
    "# Test for normality using Anderson-Darling test\n",
    "normal_columns = []\n",
    "non_normal_columns = []\n",
    "\n",
    "for column in outlier_columns:\n",
    "    result = anderson(train_encoded[column])\n",
    "    if result.statistic < result.critical_values[2]:  # 5% significance level\n",
    "        normal_columns.append(column)\n",
    "        print(f\"✓ {column}: Normal distribution (AD stat={result.statistic:.3f})\")\n",
    "    else:\n",
    "        non_normal_columns.append(column)\n",
    "        print(f\"✗ {column}: Non-normal distribution (AD stat={result.statistic:.3f})\")\n",
    "\n",
    "print(f\"\\nNormal columns: {len(normal_columns)}\")\n",
    "print(f\"Non-normal columns: {len(non_normal_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from normal columns using Z-score method\n",
    "original_shape = train_encoded.shape[0]\n",
    "\n",
    "if normal_columns:\n",
    "    z_scores = zscore(train_encoded[normal_columns])\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "    filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "    train_encoded = train_encoded[filtered_entries]\n",
    "    print(f\"✓ Z-score outlier removal: {original_shape - train_encoded.shape[0]} rows removed\")\n",
    "\n",
    "# Remove outliers from non-normal columns using IQR method\n",
    "def remove_outliers_iqr(df, columns, multiplier=1.5):\n",
    "    \"\"\"Remove outliers using IQR method\"\"\"\n",
    "    for column in columns:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - multiplier * IQR\n",
    "        upper_bound = Q3 + multiplier * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "if non_normal_columns:\n",
    "    shape_before = train_encoded.shape[0]\n",
    "    train_encoded = remove_outliers_iqr(train_encoded, non_normal_columns)\n",
    "    print(f\"✓ IQR outlier removal: {shape_before - train_encoded.shape[0]} rows removed\")\n",
    "\n",
    "print(f\"\\nFinal training shape: {train_encoded.shape}\")\n",
    "print(f\"Total rows removed: {original_shape - train_encoded.shape[0]} ({((original_shape - train_encoded.shape[0]) / original_shape * 100):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ef0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers after removal\n",
    "plt.figure(figsize=(20, 15))\n",
    "for i, column in enumerate(outlier_columns, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.boxplot(data=train_encoded, y=column, color='lightgreen')\n",
    "    plt.title(f'{column}')\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Outliers - After Removal', fontsize=16, y=1.001)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Outlier removal complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b0f43",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 7: FEATURE ENGINEERING\n",
    "**Function:** `engineer_features(df)`\n",
    "\n",
    "**Purpose:** Create derived features based on domain knowledge\n",
    "\n",
    "**Inputs:**\n",
    "- `df` (pd.DataFrame): Dataset to enhance\n",
    "\n",
    "**Outputs:**\n",
    "- `df_engineered` (pd.DataFrame): Dataset with new features\n",
    "\n",
    "**Dependencies:** BLOCK 6 (requires cleaned data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf7858",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create new features\n",
    "# 1. Total calls across all periods\n",
    "train_encoded['Total calls'] = (train_encoded['Total day calls'] + \n",
    "                                  train_encoded['Total eve calls'] + \n",
    "                                  train_encoded['Total night calls'] + \n",
    "                                  train_encoded['Total intl calls'])\n",
    "\n",
    "test_encoded['Total calls'] = (test_encoded['Total day calls'] + \n",
    "                                test_encoded['Total eve calls'] + \n",
    "                                test_encoded['Total night calls'] + \n",
    "                                test_encoded['Total intl calls'])\n",
    "\n",
    "print(\"✓ Created 'Total calls' feature\")\n",
    "\n",
    "# 2. Total charge across all periods\n",
    "train_encoded['Total charge'] = (train_encoded['Total day charge'] + \n",
    "                                   train_encoded['Total eve charge'] + \n",
    "                                   train_encoded['Total night charge'] + \n",
    "                                   train_encoded['Total intl charge'])\n",
    "\n",
    "test_encoded['Total charge'] = (test_encoded['Total day charge'] + \n",
    "                                 test_encoded['Total eve charge'] + \n",
    "                                 test_encoded['Total night charge'] + \n",
    "                                 test_encoded['Total intl charge'])\n",
    "\n",
    "print(\"✓ Created 'Total charge' feature\")\n",
    "\n",
    "# 3. Customer service calls rate (normalized by account length)\n",
    "train_encoded['CScalls Rate'] = train_encoded['Customer service calls'] / train_encoded['Account length']\n",
    "test_encoded['CScalls Rate'] = test_encoded['Customer service calls'] / test_encoded['Account length']\n",
    "\n",
    "print(\"✓ Created 'CScalls Rate' feature\")\n",
    "\n",
    "print(f\"\\nNew features summary:\")\n",
    "print(f\"  - Total calls: Aggregates all call types\")\n",
    "print(f\"  - Total charge: Aggregates all charges (validates hypothesis 2)\")\n",
    "print(f\"  - CScalls Rate: Service calls per account day (validates hypothesis 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize engineered features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.histplot(data=train_encoded, x='Total charge', hue='Churn', kde=True, bins=30, ax=axes[0])\n",
    "axes[0].set_title('Total Charge Distribution by Churn')\n",
    "\n",
    "sns.histplot(data=train_encoded, x='Total calls', hue='Churn', kde=True, bins=30, ax=axes[1])\n",
    "axes[1].set_title('Total Calls Distribution by Churn')\n",
    "\n",
    "sns.histplot(data=train_encoded, x='CScalls Rate', hue='Churn', kde=True, bins=30, ax=axes[2])\n",
    "axes[2].set_title('CS Calls Rate Distribution by Churn')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature engineering complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fbcbf",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 8: FEATURE SELECTION (CORRELATION-BASED)\n",
    "**Function:** `select_features_correlation(df, threshold, features_to_drop)`\n",
    "\n",
    "**Purpose:** Remove highly correlated and redundant features\n",
    "\n",
    "**Inputs:**\n",
    "- `df` (pd.DataFrame): Dataset with all features\n",
    "- `threshold` (float): Correlation threshold\n",
    "- `features_to_drop` (list): Manual feature list to remove\n",
    "\n",
    "**Outputs:**\n",
    "- `df_selected` (pd.DataFrame): Dataset with selected features\n",
    "- `dropped_features` (list): List of removed features\n",
    "\n",
    "**Dependencies:** BLOCK 7 (requires engineered features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88059f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CORRELATION-BASED FEATURE SELECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyze correlations before removal\n",
    "correlation_cols = [\n",
    "    'Account length', 'Total day minutes', 'Voice mail plan', 'Number vmail messages',\n",
    "    'Total day calls', 'Total day charge', 'Total eve minutes', 'Total eve calls',\n",
    "    'Total eve charge', 'Total night minutes', 'Total night calls', 'Total night charge',\n",
    "    'Total intl minutes', 'Total intl calls', 'Total intl charge'\n",
    "]\n",
    "\n",
    "corr_matrix = train_encoded[correlation_cols].corr()\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", center=0)\n",
    "plt.title('Correlation Matrix - Before Feature Removal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Remove highly correlated features (correlation > 0.9 with engineered features)\n",
    "correlated_features = [\n",
    "    'Total day minutes',    # Highly correlated with Total day charge (>0.99)\n",
    "    'Total eve minutes',    # Highly correlated with Total eve charge (>0.99)\n",
    "    'Total night minutes',  # Highly correlated with Total night charge (>0.99)\n",
    "    'Total intl minutes',   # Highly correlated with Total intl charge (>0.99)\n",
    "    'Voice mail plan'       # Redundant with Number vmail messages\n",
    "]\n",
    "\n",
    "train_encoded.drop(correlated_features, axis=1, inplace=True)\n",
    "test_encoded.drop(correlated_features, axis=1, inplace=True)\n",
    "\n",
    "print(f\"✓ Removed {len(correlated_features)} highly correlated features:\")\n",
    "for feat in correlated_features:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "# Visualize correlations after removal\n",
    "remaining_numeric_cols = [\n",
    "    'Account length', 'Number vmail messages', 'Total day calls', 'Total day charge',\n",
    "    'Total eve calls', 'Total eve charge', 'Total night calls', 'Total night charge',\n",
    "    'Total intl calls', 'Total intl charge', 'Total calls', 'Total charge', 'CScalls Rate'\n",
    "]\n",
    "\n",
    "corr_matrix_clean = train_encoded[remaining_numeric_cols].corr()\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix_clean, annot=True, cmap='coolwarm', fmt=\".2f\", center=0)\n",
    "plt.title('Correlation Matrix - After Feature Removal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal shapes:\")\n",
    "print(f\"  Training: {train_encoded.shape}\")\n",
    "print(f\"  Test: {test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d28238",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 9: DATA PREPARATION FOR MODELING\n",
    "**Function:** `prepare_data_for_modeling(train_df, test_df, target_col)`\n",
    "\n",
    "**Purpose:** Split features/target and prepare final datasets for modeling\n",
    "\n",
    "**Inputs:**\n",
    "- `train_df` (pd.DataFrame): Processed training dataset\n",
    "- `test_df` (pd.DataFrame): Processed test dataset\n",
    "- `target_col` (str): Target column name\n",
    "\n",
    "**Outputs:**\n",
    "- `X_train` (pd.DataFrame): Training features\n",
    "- `y_train` (pd.Series): Training labels\n",
    "- `X_test` (pd.DataFrame): Test features\n",
    "- `y_test` (pd.Series): Test labels\n",
    "\n",
    "**Dependencies:** BLOCK 8 (requires feature-selected data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee11d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATA PREPARATION FOR MODELING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_encoded.drop(['Churn'], axis=1)\n",
    "y_train = train_encoded['Churn']\n",
    "\n",
    "X_test = test_encoded.drop(['Churn'], axis=1)\n",
    "y_test = test_encoded['Churn']\n",
    "\n",
    "print(f\"Training set:\")\n",
    "print(f\"  Features: {X_train.shape}\")\n",
    "print(f\"  Target: {y_train.shape}\")\n",
    "print(f\"  Class distribution: {y_train.value_counts().to_dict()}\")\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Features: {X_test.shape}\")\n",
    "print(f\"  Target: {y_test.shape}\")\n",
    "print(f\"  Class distribution: {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "# Check class balance\n",
    "churn_rate_train = y_train.mean() * 100\n",
    "churn_rate_test = y_test.mean() * 100\n",
    "\n",
    "print(f\"\\nChurn rate:\")\n",
    "print(f\"  Training: {churn_rate_train:.2f}%\")\n",
    "print(f\"  Test: {churn_rate_test:.2f}%\")\n",
    "\n",
    "if churn_rate_train < 30:\n",
    "    print(\"\\n⚠ Warning: Imbalanced dataset detected. Resampling recommended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9fcdcb",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 10: DATA BALANCING\n",
    "**Function:** `balance_dataset(X, y, sampling_strategy, random_state)`\n",
    "\n",
    "**Purpose:** Balance imbalanced dataset using SMOTEENN\n",
    "\n",
    "**Inputs:**\n",
    "- `X` (pd.DataFrame): Features\n",
    "- `y` (pd.Series): Labels\n",
    "- `sampling_strategy` (float): Desired minority/majority ratio\n",
    "- `random_state` (int): Random seed\n",
    "\n",
    "**Outputs:**\n",
    "- `X_resampled` (np.ndarray): Balanced features\n",
    "- `y_resampled` (np.ndarray): Balanced labels\n",
    "- `balance_report` (dict): Class distribution before/after\n",
    "\n",
    "**Dependencies:** BLOCK 9 (requires separated features and target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f1c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATA BALANCING (SMOTEENN)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Store original distribution\n",
    "original_distribution = y_train.value_counts().to_dict()\n",
    "print(f\"Original class distribution: {original_distribution}\")\n",
    "\n",
    "# Apply SMOTEENN (SMOTE + Edited Nearest Neighbors)\n",
    "desired_ratio = 30 / 70  # Target 30% minority class\n",
    "smote_enn = SMOTEENN(sampling_strategy=desired_ratio, random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Report new distribution\n",
    "new_distribution = pd.Series(y_resampled).value_counts().to_dict()\n",
    "print(f\"\\nResampled class distribution: {new_distribution}\")\n",
    "print(f\"New dataset size: {len(y_resampled)} samples\")\n",
    "print(f\"Minority class ratio: {(new_distribution.get(1, 0) / len(y_resampled) * 100):.2f}%\")\n",
    "\n",
    "print(\"\\n✓ Data balancing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da6fc6",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 11: FEATURE SCALING\n",
    "**Function:** `scale_features(X_train, X_test, return_scaler)`\n",
    "\n",
    "**Purpose:** Standardize features using StandardScaler\n",
    "\n",
    "**Inputs:**\n",
    "- `X_train` (np.ndarray): Training features\n",
    "- `X_test` (np.ndarray): Test features\n",
    "- `return_scaler` (bool): Whether to return scaler object\n",
    "\n",
    "**Outputs:**\n",
    "- `X_train_scaled` (np.ndarray): Scaled training features\n",
    "- `X_test_scaled` (np.ndarray): Scaled test features\n",
    "- `scaler` (StandardScaler): Fitted scaler (optional)\n",
    "\n",
    "**Dependencies:** BLOCK 10 (requires balanced data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901496a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FEATURE SCALING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize and fit scaler on training data only\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"✓ Features scaled using StandardScaler\")\n",
    "print(f\"  Training shape: {X_train_scaled.shape}\")\n",
    "print(f\"  Test shape: {X_test_scaled.shape}\")\n",
    "print(f\"\\nScaling parameters:\")\n",
    "print(f\"  Mean: {scaler.mean_[:5]}... (first 5 features)\")\n",
    "print(f\"  Std: {scaler.scale_[:5]}... (first 5 features)\")\n",
    "\n",
    "# Verify scaling\n",
    "print(f\"\\nScaled data statistics:\")\n",
    "print(f\"  Mean: {X_train_scaled.mean():.6f}\")\n",
    "print(f\"  Std: {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae8a69",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 12: BASELINE MODEL COMPARISON\n",
    "**Function:** `compare_baseline_models(X_train, y_train, X_test, y_test)`\n",
    "\n",
    "**Purpose:** Train and compare multiple classification algorithms\n",
    "\n",
    "**Inputs:**\n",
    "- `X_train` (np.ndarray): Scaled training features\n",
    "- `y_train` (np.ndarray): Training labels\n",
    "- `X_test` (np.ndarray): Scaled test features\n",
    "- `y_test` (np.ndarray): Test labels\n",
    "\n",
    "**Outputs:**\n",
    "- `results_df` (pd.DataFrame): Comparison metrics for all models\n",
    "- `trained_models` (dict): Dictionary of fitted models\n",
    "\n",
    "**Dependencies:** BLOCK 11 (requires scaled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa07a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BASELINE MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', random_state=RANDOM_STATE),\n",
    "    \"Support Vector Machine\": SVC(class_weight='balanced', random_state=RANDOM_STATE),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced', random_state=RANDOM_STATE),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=RANDOM_STATE),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=RANDOM_STATE),\n",
    "    \"XGBoost\": XGBClassifier(random_state=RANDOM_STATE),\n",
    "    \"Neural Network\": MLPClassifier(random_state=RANDOM_STATE, max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "    # Train\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_scaled, y_resampled)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Train Time (s)': train_time\n",
    "    })\n",
    "    \n",
    "    trained_models[model_name] = model\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"\\n✓ Best model: {results_df.iloc[0]['Model']} ({results_df.iloc[0]['Accuracy']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db133440",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 13: HYPERPARAMETER OPTIMIZATION\n",
    "**Function:** `optimize_hyperparameters(model_type, X_train, y_train, X_test, y_test, n_trials)`\n",
    "\n",
    "**Purpose:** Optimize model hyperparameters using Optuna\n",
    "\n",
    "**Inputs:**\n",
    "- `model_type` (str): Type of model ('random_forest' or 'xgboost')\n",
    "- `X_train`, `y_train`: Training data\n",
    "- `X_test`, `y_test`: Test data\n",
    "- `n_trials` (int): Number of optimization trials\n",
    "\n",
    "**Outputs:**\n",
    "- `best_model` (estimator): Model with optimized hyperparameters\n",
    "- `best_params` (dict): Best parameters found\n",
    "- `study` (optuna.Study): Optimization study object\n",
    "\n",
    "**Dependencies:** BLOCK 12 (requires baseline comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"HYPERPARAMETER OPTIMIZATION - RANDOM FOREST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def objective_rf(trial):\n",
    "    \"\"\"Optuna objective function for Random Forest\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30, step=5),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'random_state': RANDOM_STATE\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_resampled)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Run optimization\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective_rf, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n✓ Optimization complete\")\n",
    "print(f\"Best accuracy: {study_rf.best_value:.4f}\")\n",
    "print(f\"Best parameters: {study_rf.best_params}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_rf_model = RandomForestClassifier(**study_rf.best_params, random_state=RANDOM_STATE)\n",
    "best_rf_model.fit(X_train_scaled, y_resampled)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_rf = best_rf_model.predict(X_test_scaled)\n",
    "print(f\"\\n Random Forest - Best Model Performance:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"HYPERPARAMETER OPTIMIZATION - XGBOOST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    \"\"\"Optuna objective function for XGBoost\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300, step=50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'random_state': RANDOM_STATE\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_resampled)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Run optimization\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n✓ Optimization complete\")\n",
    "print(f\"Best accuracy: {study_xgb.best_value:.4f}\")\n",
    "print(f\"Best parameters: {study_xgb.best_params}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_xgb_model = XGBClassifier(**study_xgb.best_params, random_state=RANDOM_STATE)\n",
    "best_xgb_model.fit(X_train_scaled, y_resampled)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_xgb = best_xgb_model.predict(X_test_scaled)\n",
    "print(f\"\\nXGBoost - Best Model Performance:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a518ee",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 14: FEATURE IMPORTANCE ANALYSIS\n",
    "**Function:** `extract_feature_importance(model, feature_names, top_n)`\n",
    "\n",
    "**Purpose:** Extract and visualize feature importances\n",
    "\n",
    "**Inputs:**\n",
    "- `model` (estimator): Trained model with feature_importances_\n",
    "- `feature_names` (list): Feature names\n",
    "- `top_n` (int): Number of top features to return\n",
    "\n",
    "**Outputs:**\n",
    "- `importance_df` (pd.DataFrame): Feature importance scores\n",
    "- `top_features` (list): Top N feature names\n",
    "\n",
    "**Dependencies:** BLOCK 13 (requires trained models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "# Random Forest Feature Importance\n",
    "rf_importances = best_rf_model.feature_importances_\n",
    "rf_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': rf_importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nRandom Forest - Top 15 Important Features:\")\n",
    "print(rf_importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# Visualize RF importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_n = 20\n",
    "sorted_idx = rf_importances.argsort()[::-1][:top_n]\n",
    "plt.barh(range(top_n), rf_importances[sorted_idx])\n",
    "plt.yticks(range(top_n), [feature_names[i] for i in sorted_idx])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest - Top 20 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# XGBoost Feature Importance\n",
    "xgb_importances = best_xgb_model.feature_importances_\n",
    "xgb_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': xgb_importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nXGBoost - Top 15 Important Features:\")\n",
    "print(xgb_importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# Visualize XGBoost importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sorted_idx = xgb_importances.argsort()[::-1][:top_n]\n",
    "plt.barh(range(top_n), xgb_importances[sorted_idx])\n",
    "plt.yticks(range(top_n), [feature_names[i] for i in sorted_idx])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('XGBoost - Top 20 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract top features for final model\n",
    "top_features_rf = rf_importance_df.head(10)['Feature'].tolist()\n",
    "top_features_xgb = xgb_importance_df.head(14)['Feature'].tolist()\n",
    "\n",
    "print(f\"\\n✓ Feature importance analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a257266",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 15: FINAL MODEL EVALUATION\n",
    "**Function:** `evaluate_model_comprehensive(model, X_test, y_test, model_name)`\n",
    "\n",
    "**Purpose:** Comprehensive model evaluation with multiple metrics\n",
    "\n",
    "**Inputs:**\n",
    "- `model` (estimator): Trained model\n",
    "- `X_test` (np.ndarray): Test features\n",
    "- `y_test` (np.ndarray): True labels\n",
    "- `model_name` (str): Model name for reporting\n",
    "\n",
    "**Outputs:**\n",
    "- `metrics_dict` (dict): All evaluation metrics\n",
    "- Displays plots and reports\n",
    "\n",
    "**Dependencies:** BLOCK 13 (requires trained models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f635629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"COMPREHENSIVE MODEL EVALUATION - XGBOOST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Select top features\n",
    "X_test_selected = X_test[top_features_xgb]\n",
    "X_resampled_selected = X_resampled[top_features_xgb]\n",
    "\n",
    "# Scale\n",
    "X_train_scaled_final = scaler.fit_transform(X_resampled_selected)\n",
    "X_test_scaled_final = scaler.transform(X_test_selected)\n",
    "\n",
    "# Train final model\n",
    "best_xgb_model.fit(X_train_scaled_final, y_resampled)\n",
    "y_pred = best_xgb_model.predict(X_test_scaled_final)\n",
    "y_pred_proba = best_xgb_model.predict_proba(X_test_scaled_final)[:, 1]\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "metrics = {}\n",
    "metrics['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "metrics['ROC AUC'] = roc_auc_score(y_test, y_pred_proba)\n",
    "metrics['Log Loss'] = log_loss(y_test, y_pred_proba)\n",
    "metrics['Cohen Kappa'] = cohen_kappa_score(y_test, y_pred)\n",
    "metrics['Matthews Corr Coef'] = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print(\"Performance Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {metrics[\"ROC AUC\"]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Comprehensive evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7840be",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 16: CROSS-VALIDATION\n",
    "**Function:** `cross_validate_model(model, X, y, cv, scoring)`\n",
    "\n",
    "**Purpose:** Perform k-fold cross-validation\n",
    "\n",
    "**Inputs:**\n",
    "- `model` (estimator): Model to validate\n",
    "- `X` (np.ndarray): Features\n",
    "- `y` (np.ndarray): Labels\n",
    "- `cv` (int): Number of folds\n",
    "- `scoring` (str): Scoring metric\n",
    "\n",
    "**Outputs:**\n",
    "- `cv_results` (dict): CV scores and statistics\n",
    "\n",
    "**Dependencies:** BLOCK 13 (requires trained models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CROSS-VALIDATION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(\n",
    "    best_xgb_model,\n",
    "    X_train_scaled_final,\n",
    "    y_resampled,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"  Individual fold scores: {cv_scores}\")\n",
    "print(f\"  Mean ROC AUC: {cv_scores.mean():.4f}\")\n",
    "print(f\"  Std ROC AUC: {cv_scores.std():.4f}\")\n",
    "print(f\"  95% Confidence Interval: [{cv_scores.mean() - 1.96*cv_scores.std():.4f}, {cv_scores.mean() + 1.96*cv_scores.std():.4f}]\")\n",
    "\n",
    "# Visualize CV scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, 6), cv_scores, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='--', label=f'Mean: {cv_scores.mean():.4f}')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('ROC AUC Score')\n",
    "plt.title('5-Fold Cross-Validation Scores')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Cross-validation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1fe421",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 17: MODEL PERSISTENCE (SAVE)\n",
    "**Function:** `save_model_artifacts(model, scaler, encoders, feature_names, output_dir)`\n",
    "\n",
    "**Purpose:** Save trained model and all preprocessing artifacts\n",
    "\n",
    "**Inputs:**\n",
    "- `model` (estimator): Trained model\n",
    "- `scaler` (StandardScaler): Fitted scaler\n",
    "- `encoders` (dict): Fitted encoders\n",
    "- `feature_names` (list): Selected feature names\n",
    "- `output_dir` (str): Output directory\n",
    "\n",
    "**Outputs:**\n",
    "- Saved files: model, scaler, encoders, metadata\n",
    "- `artifact_paths` (dict): Paths to saved files\n",
    "\n",
    "**Dependencies:** BLOCK 15 (requires final trained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODEL PERSISTENCE - SAVING ARTIFACTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "import os\n",
    "model_dir = './models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_dir, 'xgboost_churn_model.pkl')\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(best_xgb_model, f)\n",
    "print(f\"✓ Model saved: {model_path}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = os.path.join(model_dir, 'scaler.pkl')\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"✓ Scaler saved: {scaler_path}\")\n",
    "\n",
    "# Save encoders\n",
    "encoders_path = os.path.join(model_dir, 'encoders.pkl')\n",
    "with open(encoders_path, 'wb') as f:\n",
    "    pickle.dump(encoders, f)\n",
    "print(f\"✓ Encoders saved: {encoders_path}\")\n",
    "\n",
    "# Save feature names\n",
    "import json\n",
    "features_path = os.path.join(model_dir, 'feature_names.json')\n",
    "with open(features_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'all_features': feature_names,\n",
    "        'selected_features': top_features_xgb,\n",
    "        'num_features': len(top_features_xgb)\n",
    "    }, f, indent=2)\n",
    "print(f\"✓ Feature names saved: {features_path}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'model_type': 'XGBoost',\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'best_params': study_xgb.best_params,\n",
    "    'metrics': metrics,\n",
    "    'cv_scores': cv_scores.tolist(),\n",
    "    'cv_mean': float(cv_scores.mean()),\n",
    "    'cv_std': float(cv_scores.std()),\n",
    "    'num_training_samples': len(y_resampled),\n",
    "    'num_test_samples': len(y_test),\n",
    "    'selected_features': top_features_xgb\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(model_dir, 'model_metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"✓ Metadata saved: {metadata_path}\")\n",
    "\n",
    "print(f\"\\n✓ All artifacts saved successfully to '{model_dir}/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead3e78b",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 18: MODEL LOADING (INFERENCE PIPELINE)\n",
    "**Function:** `load_model_artifacts(model_dir)`\n",
    "\n",
    "**Purpose:** Load saved model and preprocessing artifacts\n",
    "\n",
    "**Inputs:**\n",
    "- `model_dir` (str): Directory containing saved artifacts\n",
    "\n",
    "**Outputs:**\n",
    "- `artifacts` (dict): Dictionary with model, scaler, encoders, metadata\n",
    "\n",
    "**Dependencies:** BLOCK 17 (requires saved artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODEL LOADING - INFERENCE PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def load_model_artifacts(model_dir='./models'):\n",
    "    \"\"\"Load all model artifacts for inference\"\"\"\n",
    "    artifacts = {}\n",
    "    \n",
    "    # Load model\n",
    "    model_path = os.path.join(model_dir, 'xgboost_churn_model.pkl')\n",
    "    with open(model_path, 'rb') as f:\n",
    "        artifacts['model'] = pickle.load(f)\n",
    "    print(f\"✓ Model loaded from: {model_path}\")\n",
    "    \n",
    "    # Load scaler\n",
    "    scaler_path = os.path.join(model_dir, 'scaler.pkl')\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        artifacts['scaler'] = pickle.load(f)\n",
    "    print(f\"✓ Scaler loaded from: {scaler_path}\")\n",
    "    \n",
    "    # Load encoders\n",
    "    encoders_path = os.path.join(model_dir, 'encoders.pkl')\n",
    "    with open(encoders_path, 'rb') as f:\n",
    "        artifacts['encoders'] = pickle.load(f)\n",
    "    print(f\"✓ Encoders loaded from: {encoders_path}\")\n",
    "    \n",
    "    # Load feature names\n",
    "    features_path = os.path.join(model_dir, 'feature_names.json')\n",
    "    with open(features_path, 'r') as f:\n",
    "        artifacts['feature_config'] = json.load(f)\n",
    "    print(f\"✓ Feature config loaded from: {features_path}\")\n",
    "    \n",
    "    # Load metadata\n",
    "    metadata_path = os.path.join(model_dir, 'model_metadata.json')\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        artifacts['metadata'] = json.load(f)\n",
    "    print(f\"✓ Metadata loaded from: {metadata_path}\")\n",
    "    \n",
    "    return artifacts\n",
    "\n",
    "# Test loading\n",
    "loaded_artifacts = load_model_artifacts('./models')\n",
    "\n",
    "print(\"\\nLoaded Artifacts Summary:\")\n",
    "print(f\"  Model Type: {loaded_artifacts['metadata']['model_type']}\")\n",
    "print(f\"  Training Date: {loaded_artifacts['metadata']['training_date']}\")\n",
    "print(f\"  Test Accuracy: {loaded_artifacts['metadata']['metrics']['Accuracy']:.4f}\")\n",
    "print(f\"  ROC AUC: {loaded_artifacts['metadata']['metrics']['ROC AUC']:.4f}\")\n",
    "print(f\"  Selected Features: {loaded_artifacts['feature_config']['num_features']}\")\n",
    "\n",
    "print(\"\\n✓ Model artifacts loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bbadbe",
   "metadata": {},
   "source": [
    "---\n",
    "## BLOCK 19: INFERENCE FUNCTION\n",
    "**Function:** `predict_churn(customer_data, artifacts)`\n",
    "\n",
    "**Purpose:** Make predictions on new customer data\n",
    "\n",
    "**Inputs:**\n",
    "- `customer_data` (pd.DataFrame or dict): New customer data\n",
    "- `artifacts` (dict): Loaded model artifacts\n",
    "\n",
    "**Outputs:**\n",
    "- `predictions` (np.ndarray): Binary predictions\n",
    "- `probabilities` (np.ndarray): Churn probabilities\n",
    "- `risk_category` (list): Risk level labels\n",
    "\n",
    "**Dependencies:** BLOCK 18 (requires loaded artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f7ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"INFERENCE FUNCTION - PREDICT CHURN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def predict_churn(customer_data, artifacts):\n",
    "    \"\"\"\n",
    "    Make churn predictions on new customer data\n",
    "    \n",
    "    Args:\n",
    "        customer_data: DataFrame or dict with customer information\n",
    "        artifacts: Loaded model artifacts from load_model_artifacts()\n",
    "    \n",
    "    Returns:\n",
    "        dict with predictions, probabilities, and risk categories\n",
    "    \"\"\"\n",
    "    # Convert dict to DataFrame if needed\n",
    "    if isinstance(customer_data, dict):\n",
    "        customer_data = pd.DataFrame([customer_data])\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    df = customer_data.copy()\n",
    "    \n",
    "    # 1. Encode categorical features\n",
    "    # Binary encoding\n",
    "    binary_mapping = {'No': 0, 'Yes': 1, False: 0, True: 1}\n",
    "    if 'International plan' in df.columns:\n",
    "        df['International plan'] = df['International plan'].map(binary_mapping)\n",
    "    if 'Voice mail plan' in df.columns:\n",
    "        df['Voice mail plan'] = df['Voice mail plan'].map(binary_mapping)\n",
    "    \n",
    "    # One-hot encoding for State and Area code\n",
    "    if 'State' in df.columns:\n",
    "        state_encoder = artifacts['encoders']['state_encoder']\n",
    "        encoded_states = state_encoder.transform(df[['State']])\n",
    "        state_columns = state_encoder.get_feature_names_out(['State'])\n",
    "        df_states = pd.DataFrame(encoded_states, columns=state_columns, index=df.index)\n",
    "        df = df.drop(['State'], axis=1)\n",
    "        df = pd.concat([df, df_states], axis=1)\n",
    "    \n",
    "    if 'Area code' in df.columns:\n",
    "        area_encoder = artifacts['encoders']['area_encoder']\n",
    "        encoded_area = area_encoder.transform(df[['Area code']])\n",
    "        area_columns = area_encoder.get_feature_names_out(['Area code'])\n",
    "        df_area = pd.DataFrame(encoded_area, columns=area_columns, index=df.index)\n",
    "        df = df.drop(['Area code'], axis=1)\n",
    "        df = pd.concat([df, df_area], axis=1)\n",
    "    \n",
    "    # 2. Engineer features\n",
    "    df['Total calls'] = (df['Total day calls'] + df['Total eve calls'] + \n",
    "                         df['Total night calls'] + df['Total intl calls'])\n",
    "    df['Total charge'] = (df['Total day charge'] + df['Total eve charge'] + \n",
    "                          df['Total night charge'] + df['Total intl charge'])\n",
    "    df['CScalls Rate'] = df['Customer service calls'] / df['Account length']\n",
    "    \n",
    "    # 3. Remove correlated features\n",
    "    correlated_features = ['Total day minutes', 'Total eve minutes', \n",
    "                           'Total night minutes', 'Total intl minutes', 'Voice mail plan']\n",
    "    df = df.drop(columns=[col for col in correlated_features if col in df.columns], errors='ignore')\n",
    "    \n",
    "    # 4. Select important features\n",
    "    selected_features = artifacts['feature_config']['selected_features']\n",
    "    df_selected = df[selected_features]\n",
    "    \n",
    "    # 5. Scale features\n",
    "    scaler = artifacts['scaler']\n",
    "    df_scaled = scaler.transform(df_selected)\n",
    "    \n",
    "    # 6. Make predictions\n",
    "    model = artifacts['model']\n",
    "    predictions = model.predict(df_scaled)\n",
    "    probabilities = model.predict_proba(df_scaled)[:, 1]\n",
    "    \n",
    "    # 7. Categorize risk\n",
    "    risk_categories = []\n",
    "    for prob in probabilities:\n",
    "        if prob < 0.3:\n",
    "            risk_categories.append('Low Risk')\n",
    "        elif prob < 0.7:\n",
    "            risk_categories.append('Medium Risk')\n",
    "        else:\n",
    "            risk_categories.append('High Risk')\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'probabilities': probabilities,\n",
    "        'risk_categories': risk_categories,\n",
    "        'churn_labels': ['No Churn' if p == 0 else 'Churn' for p in predictions]\n",
    "    }\n",
    "\n",
    "# Test inference with sample data from test set\n",
    "sample_customer = test_df.iloc[0:1].drop('Churn', axis=1)\n",
    "\n",
    "print(\"Sample Customer Data:\")\n",
    "print(sample_customer.head())\n",
    "\n",
    "# Make prediction\n",
    "result = predict_churn(sample_customer, loaded_artifacts)\n",
    "\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(f\"  Prediction: {result['churn_labels'][0]}\")\n",
    "print(f\"  Churn Probability: {result['probabilities'][0]:.2%}\")\n",
    "print(f\"  Risk Category: {result['risk_categories'][0]}\")\n",
    "\n",
    "print(\"\\n✓ Inference pipeline tested successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d362de",
   "metadata": {},
   "source": [
    "---\n",
    "## SUMMARY: MODULAR PIPELINE STRUCTURE\n",
    "\n",
    "### Identified Logical Blocks:\n",
    "\n",
    "**1. Data Loading & Validation** (Blocks 2-3)\n",
    "   - `load_data()` - Load CSV files\n",
    "   - `validate_data_quality()` - Quality checks\n",
    "\n",
    "**2. Exploratory Data Analysis** (Block 4)\n",
    "   - `perform_eda()` - Generate visualizations and statistics\n",
    "\n",
    "**3. Data Preprocessing** (Blocks 5-6)\n",
    "   - `encode_categorical_features()` - Encode categorical variables\n",
    "   - `remove_outliers()` - Statistical outlier removal\n",
    "\n",
    "**4. Feature Engineering** (Blocks 7-8)\n",
    "   - `engineer_features()` - Create derived features\n",
    "   - `select_features_correlation()` - Remove correlated features\n",
    "\n",
    "**5. Data Preparation** (Blocks 9-11)\n",
    "   - `prepare_data_for_modeling()` - Split features/target\n",
    "   - `balance_dataset()` - Handle class imbalance\n",
    "   - `scale_features()` - Standardize features\n",
    "\n",
    "**6. Model Training** (Blocks 12-13)\n",
    "   - `compare_baseline_models()` - Train multiple algorithms\n",
    "   - `optimize_hyperparameters()` - Tune best models\n",
    "\n",
    "**7. Model Analysis** (Blocks 14-16)\n",
    "   - `extract_feature_importance()` - Analyze feature importance\n",
    "   - `evaluate_model_comprehensive()` - Full evaluation metrics\n",
    "   - `cross_validate_model()` - K-fold cross-validation\n",
    "\n",
    "**8. Model Persistence** (Blocks 17-18)\n",
    "   - `save_model_artifacts()` - Save model and artifacts\n",
    "   - `load_model_artifacts()` - Load for inference\n",
    "\n",
    "**9. Inference Pipeline** (Block 19)\n",
    "   - `predict_churn()` - End-to-end prediction on new data\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "1. Convert each block into a standalone Python function\n",
    "2. Create unit tests for each function\n",
    "3. Build a production API (FastAPI/Flask)\n",
    "4. Implement monitoring and logging\n",
    "5. Set up CI/CD pipeline"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
